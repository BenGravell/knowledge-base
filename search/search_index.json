{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Knowledge Base","text":"<p>Welcome to my curated collection of research papers, ideas, and explanations in the fields of motion planning, optimization, robotics, machine learning, and more, where I:</p> <ul> <li>Document and reflect on academic papers.</li> <li>Explore foundational and emerging topics.</li> <li>Build explainer content for complex concepts.</li> <li>Organize my growing personal understanding in a structured, searchable way.</li> </ul> <p>Whether you're here to deepen your understanding, explore specific research areas, or follow my perspective through complex topics, I hope you find the content useful and engaging.</p>"},{"location":"#contribute-or-reach-out","title":"Contribute or Reach Out","text":"<p>If you'd like to suggest papers, discuss an idea, or share feedback, feel free to reach out to me on GitHub.</p> <p>Happy exploring!</p>"},{"location":"papers/1706_03762/","title":"Attention Is All You Need","text":"<p>Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin</p> <p>Published: 2017 (Journal Paper)</p> <p>Source: 31st Conference on Neural Information Processing Systems (NIPS)</p> <p>Algorithm: Transformer</p>"},{"location":"papers/1706_03762/#summary","title":"Summary","text":"<p>The paper introduces the Transformer architecture, a novel neural network model based on attention mechanisms, demonstrating state-of-the-art performance on NLP tasks.</p>"},{"location":"papers/1706_03762/#links","title":"Links","text":"<ul> <li>Paper PDF</li> </ul>"},{"location":"papers/1706_03762/#tags","title":"Tags","text":"<ul> <li> <p>Transformers</p> </li> <li> <p>NLP</p> </li> <li> <p>Deep learning</p> </li> </ul>"},{"location":"papers/1978_doyle_guaranteed_margins_for_lqg/","title":"Guaranteed margins for LQG regulators","text":"<p>Authors: John C. Doyle</p> <p>Published: 1978 (Journal Paper)</p> <p>Source: IEEE Transactions on Automatic Control</p> <p>Algorithm: LQG</p>"},{"location":"papers/1978_doyle_guaranteed_margins_for_lqg/#summary","title":"Summary","text":"<p>There are none.</p>"},{"location":"papers/1978_doyle_guaranteed_margins_for_lqg/#links","title":"Links","text":"<ul> <li>Paper PDF</li> </ul>"},{"location":"papers/1978_doyle_guaranteed_margins_for_lqg/#tags","title":"Tags","text":"<ul> <li> <p>Linear Quadratic Gaussian (LQG)</p> </li> <li> <p>Robust control</p> </li> </ul>"},{"location":"papers/1998_lavalle_rapidly_exploring_random_trees/","title":"Rapidly-exploring Random Trees: A New Tool for Path Planning","text":"<p>Authors: Steven M. LaValle</p> <p>Published: 1998 (Tech Report)</p> <p>Source: University of Illinois</p> <p>Algorithm: RRT</p>"},{"location":"papers/1998_lavalle_rapidly_exploring_random_trees/#summary","title":"Summary","text":"<p>Introduces RRTs for sampling-based motion planning in high-dimensional configuration spaces.</p>"},{"location":"papers/1998_lavalle_rapidly_exploring_random_trees/#links","title":"Links","text":"<ul> <li>Paper PDF</li> </ul>"},{"location":"papers/1998_lavalle_rapidly_exploring_random_trees/#tags","title":"Tags","text":"<ul> <li> <p>Motion planning</p> </li> <li> <p>Path planning</p> </li> <li> <p>Sampling-based</p> </li> <li> <p>RRT</p> </li> </ul>"},{"location":"papers/1999_lavalle_randomized_kinodynamic_planning/","title":"Randomized Kinodynamic Planning","text":"<p>Authors: Steven M. LaValle, James J. Kuffner, Jr.</p> <p>Published: 1999 (Conference Paper)</p> <p>Source: IEEE International Conference on Robotics and Automation (ICRA)</p> <p>Algorithm: RRT</p>"},{"location":"papers/1999_lavalle_randomized_kinodynamic_planning/#summary","title":"Summary","text":"<p>Introduces RRTs for sampling-based trajectory planning in high-dimensional configuration spaces.</p>"},{"location":"papers/1999_lavalle_randomized_kinodynamic_planning/#links","title":"Links","text":"<ul> <li>Paper PDF</li> </ul>"},{"location":"papers/1999_lavalle_randomized_kinodynamic_planning/#additional-links","title":"Additional Links","text":"<ul> <li>https://ieeexplore.ieee.org/document/770022</li> </ul>"},{"location":"papers/1999_lavalle_randomized_kinodynamic_planning/#tags","title":"Tags","text":"<ul> <li> <p>Motion planning</p> </li> <li> <p>Kinodynamic planning</p> </li> <li> <p>Trajectory planning</p> </li> <li> <p>Sampling-based</p> </li> <li> <p>RRT</p> </li> </ul>"},{"location":"papers/2511_00814/","title":"Real-Time Learning of Predictive Dynamic Obstacle Models for Robotic Motion Planning","text":"<p>Authors: Stella Kombo, Masih Haseli, Skylar Wei, Joel W. Burdick</p> <p>Published: 2025 (Conference Paper)</p>"},{"location":"papers/2511_00814/#summary","title":"Summary","text":"<p>Autonomous systems often must predict the motions of nearby agents from partial and noisy data. This paper asks and answers the question: \"can we learn, in real-time, a nonlinear predictive model of another agent's motions?\" The problem is tackled by using a special kind of Dynamic Mode Decomposition (DMD), which comes from the Koopman operator theory, to learn a model of the agent motion. The model also produces uncertainty estimates, which is useful for downstream risk-aware planning &amp; control. This paper combines a lot of smaller techniques (Hankel-DMD, Cadzow projection, Singular Value Hard Thresholding (SVHT), etc.) together into a rather intricate bells-and-whistles learner, but that in itself is nice as it provides the reader some clues into those techniques.</p>"},{"location":"papers/2511_00814/#links","title":"Links","text":"<ul> <li>Paper PDF</li> </ul>"},{"location":"papers/2511_00814/#tags","title":"Tags","text":"<ul> <li> <p>Prediction</p> </li> <li> <p>Dynamic Mode Decomposition</p> </li> </ul>"}]}